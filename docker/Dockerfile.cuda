# GPU-enabled image using PyTorch CUDA wheels (host must have NVIDIA driver + nvidia-container-toolkit)
FROM python:3.11-slim

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    # Optional: improve CUDA alloc behavior
    PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

RUN apt-get update && apt-get install -y --no-install-recommends \
    git ca-certificates curl tini \
 && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY pyproject.toml README.md ./
COPY env/requirements.txt env/requirements.txt

# Install FRL first
RUN python -m pip install -U pip wheel setuptools \
 && pip install .

# Install CUDA-enabled PyTorch stack (CUDA 12.1 wheels bundle runtime)
RUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Copy source
COPY frl/ frl/
COPY scripts/ scripts/
COPY configs/ configs/
COPY examples/ examples/
COPY frl/scenarios/ frl/scenarios/
COPY docs/ docs/

RUN mkdir -p /app/results/logs /app/results/figures /app/data

RUN useradd -m -u 1000 appuser
USER appuser

WORKDIR /app
ENTRYPOINT ["/usr/bin/tini", "--"]
CMD ["python", "-c", "import torch; print('FRL CUDA image ready; CUDA:', torch.cuda.is_available())"]
